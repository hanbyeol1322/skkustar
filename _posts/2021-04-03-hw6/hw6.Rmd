---
title: "전처리후 oulier 제거와 training"
description: |
  hw6
author:
  - name: hanbyeol
    url: {}
date: 04-03-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

2주 전에 전처리 하나만으로 점수가 엄청 오른 것을 확인 할 수 있었다. 
이전 전처리 후 **oulier의 제거**와 **학습**을 통해 좀 더 예측력을 올려보자!!!!

# 1. Outlier 제거

outlier를 제거하기 위해 데이터를 다시 불러와서 시작한당
준비단계....

## 1.1  Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(skimr)
library(knitr)
theme_set(theme_bw())
```

## 1.2 Data load

```{r}
file_path <- "/cloud/project"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
test <- read_csv(file.path(file_path, "test.csv"))%>% 
  janitor::clean_names()
train <- read_csv(file.path(file_path, "train.csv"))%>% 
  janitor::clean_names() 
```

## 1.3 Outliers 확인하기

-   gr_liv_area 변수에 있는 outlier를 확인해보자!

* Any thoughts about right 4 points?

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = gr_liv_area, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```
4500이상 되는 값들이 유독 튀는 것을 확인 할 수 있다. 
4500 이상 되는 2개의 값을 필터 씌운 뒤에 다시 
train data로 넣어보자 **%<>%**

```{r}
# outliers 
train %>%
  filter(gr_liv_area > 4500) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(!(gr_liv_area > 4500))
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = gr_liv_area, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "After removing outliers")
```
outlier를 지우니 추세가 눈에 확 들어온다!

-   total_bsmt_sf 변수에 있는 outlier를 확인해보자!

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = total_bsmt_sf, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```
total_bsmt_sf가 3000 이상 되는 값들이 튀는 것처럼 보인다. 

outlier점 3개중에  2개를 지웠다. 
(왜 로그값이 13보다 작은 값들을 지우셨는지는 좀 더 생각해보자)

```{r}
# outliers 
train %>%
  filter(total_bsmt_sf > 3000 &
                   log(sale_price) < 13) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(!(total_bsmt_sf > 3000 &
                   log(sale_price) < 13))
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = total_bsmt_sf, 
             y = log(sale_price))) +
  geom_point() +
  labs(title = "After removing outliers")
```
잘 지워졌당~!


-   garage_area 변수에 있는 outlier를 확인해보자!

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = garage_area, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```

1230보다 큰 3개의 점이 거슬린다.. 저걸 지워보쟈

```{r}
# outliers 
train %>% 
  filter(garage_area > 1230) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(garage_area <= 1230)
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = garage_area, 
             y = log(sale_price))) +
  geom_point() +
  labs(title = "After removing outliers")
```
잘 지워졌구나 ~!


# 2. training

이제 거슬리는 outliers을 지웠으니 학습을 통해 예측력을 높여보자 !!!

1번에서 outliers를 제거한 train set을 이용해서 training 해볼 것이다.!

먼저 outlier를 제거한 train과 test를 다시 전처리해준다. 

```{r}
 all_data <- bind_rows(train, test)
 names(all_data)[1:10]

```

-   Make recipe

```{r}
housing_recipe <- all_data %>% 
  recipe(sale_price ~ .) %>%
  step_rm(id) %>% 
  step_log(sale_price) %>%
  step_modeimpute(all_nominal()) %>% 
  step_dummy(all_nominal()) %>% 
  step_meanimpute(all_predictors()) %>%
  step_normalize(all_predictors()) %>% 
  prep(training = all_data)
print(housing_recipe)
```

-   `juice` the all_data2 and split

```{r}
all_data2 <- juice(housing_recipe)
```

We are done for preprocessing. Let's split the data set.

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]
```

전처리가 다 끝났으면 이제 어떻게 학습할 것인지 알아보자

## 2.1 Elastic net

train set을 validation set으로 다시 분리 시킬 것이다.
70%는 학습용으로 남겨놓아라. 30%는 평가용!!

```{r}
set.seed(2021)
validation_split <- validation_split(train2, prop = 0.7)
#validation_split <- vfold_cv(train2, v = 10, strata = sale_price)
# actual split id stored in the following
# validation_split$splits[[1]]$in_id
# the whole point is that it's there and trust tidymodels :)
# head(validation_split$splits[[1]]$in_id)
``` 

이것이 실제로 어떻게 나눠져 있는지 확인하려면

in_id : 학습 할 때 사용하는 것
out_id : 평가 할 때 사용하는 것

```{r}
validation_split$splits[[1]]$in_id
head(validation_split$splits[[1]]$in_id)
```
### 2.1.1 Ridge Regression

이제 tune을 해야하는데 Elastic net에서 $\alpha$(=mixture),penalty(=lambda)

ridge regression: Mixture=0

penalty는 아직 안정했음 : tune 할 것이다.

-   Set the tuning spec
람다의 후보군을 여러개 남기기 위해서 

*tune_spec*: ridge regression에 penalty는 아직 정해지지 않은 상태

*glmnet*: elastic net을 사용하기 위한 packaages

*param_grid* : 후보가 될 수 있는 람다의 값이 들어있음(하나하나 학습 시킬 것)0이 없고, 1이 무한대인 상태!

*grid_regular(levels = 50)* : 0에서 1까지 중에 균등하게 50개를 뽑은 것

```{r}
tune_spec <- linear_reg(penalty = tune(),
                        mixture = 0) %>% #ridge
  set_engine("glmnet")
param_grid <- grid_regular(penalty(), levels = 50)
                           # mixture(),
                           # levels = list(penalty = 100,
                                         # mixture = 5))
```

-   Set workflow()

평가하기 위한 모델을 만들기

```{r}
workflow <- workflow() %>%
  add_model(tune_spec) %>% 
  add_formula(sale_price ~ .)
```


-   Tuning $\lambda$ and $\alpha$
*validation_split*(학습, test데이터)에다가 param_grid를 fitting한다.

어떤 것이 좋은지 평가하는 방식은 rmse(soot mean square error)를 이용하겠다.

-> *tune_result*에 각 람다 값에 대한 퍼포먼스가 담기게 된다. 

```{r}
library(tictoc)
doParallel::registerDoParallel()
tic()
tune_result <- workflow %>% 
  tune_grid(validation_split,
            grid = param_grid,
            metrics = metric_set(rmse))
toc()
```
*collect_metrics()*: 퍼포먼스가 담긴 것들을 모아봐라

*mean* 값: rmse값(validation에서 나온 것 들의 평균)

우리의 목표: **mean 값이 최소**가 되는 **penalty**값을 구하는 것

```{r}
tune_result %>% 
  collect_metrics()
```


-   Visualization of the tunning result

mixture은 지금 없으니까(ridge) 잠시 나가있어 

```{r}
tune_best <- tune_result %>% select_best(metric = "rmse")
tune_best$penalty
# tune_best$mixture
```

tune_result안네 penalty대비 rmse의 값을 보여주는 plot

```{r message=FALSE}
tune_result %>%
  collect_metrics() %>%
  #filter(mixture == tune_best$mixture) %>%
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 1.5) +
  scale_x_log10() +
  theme(legend.position = "none") +
  labs(title = "RMSE")
```

*show_best()*: mean값을 최소로 만들어주는 값들의 몇개를 보여준다 

```{r}
tune_result %>% show_best()
```

-   Set **Ridge regression model** and fitting

Set `mixture` is equal to zero refering the Ridge regression in `glmnet` since the 

위에서 구한 값으로 train2를 학습시킨다. 

```{r message=FALSE, warning=FALSE}
elastic_model <- 
    linear_reg(penalty = tune_best$penalty, # 0.095
               mixture = 0) %>%
    set_engine("glmnet")
elastic_fit <- 
    elastic_model %>% 
    fit(sale_price ~ ., data = train2)
options(max.print = 10)
elastic_fit %>% 
    tidy() %>% 
    filter(estimate > 0.001)
```

-   Prediction and submit

```{r warning=FALSE}
result <- predict(elastic_fit, test2)
result %>% head()
```

```{r}
submission <- read_csv(file.path(file_path, "sample_submission.csv"))
submission$SalePrice <- exp(result$.pred)
write.csv(submission, row.names = FALSE,
          "baseline_regression.csv")
```

오늘 배운 것은 train을 둘로 쪼개서 하나는 가상의 test set으로 하고 하나는 train으로 

평가하는 validation set이 test set과 비슷하면 좋겟지만, 비슷하지 못할 경우를 대비해서 cross validation을 진행한다.!!

방법은 validation set을 여러개로 만드는 것인ㄷㅔ,,
v=10: train data를 10개로 나누되, saleprice가 골고루 나눠서 담길 수 있도록 하라. 

```{r}
set.seed(2021)
#validation_split <- validation_split(train2, prop = 0.7)
validation_split <- vfold_cv(train2, v = 10, strata = sale_price)
# actual split id stored in the following
# validation_split$splits[[1]]$in_id
# the whole point is that it's there and trust tidymodels :)
# head(validation_split$splits[[1]]$in_id)

```

알파와 람다를 정하지 않고 tune을 하라. 두가지를 고르는 것이니까 mixture도 tune으로 해주기


```{r}
tune_spec <- linear_reg(penalty = tune(),
                        mixture = tune()) %>% #ridge
  set_engine("glmnet")
param_grid <- grid_regular(penalty(),
                           mixture(),
                           levels = list(penalty = 100,
                                         mixture = 5))
```

각 fold에 대해서 가능한 후보군 집합이 있다. 
rmse말고 다른 (mae)것도 함 께 볼 수 있다 .

*에러남*
```{r}
# library(tictoc)
# doParallel::registerDoParallel()
# tic()
# tune_result <- workflow %>% 
#   tune_grid(validation_split,
#             grid = param_grid,
#             metrics = metric_set(rmse,mae))
# toc()
```


```{r}
tune_best <- tune_result %>% select_best(metric = "rmse")
tune_best$penalty
tune_best$mixture
```

결과에 mixture=0이 나오면 regression방법으로 lasso 보다 ridge를 사용하는 것이 예측력에 더 좋다는 것을 확인 할 수 있음

*에러*
```{r message=FALSE}
# tune_result %>%
#   collect_metrics() %>%
#   filter(mixture == tune_best$mixture) %>%
#   ggplot(aes(penalty, mean, color = .metric)) +
#   geom_line(size = 1.5) +
#   scale_x_log10() +
#   theme(legend.position = "none") +
#   labs(title = "RMSE")

```

show_best(): mean값을 최소로 만들어주는 값들의 몇개를 보여준다 
```{r}
tune_result %>% show_best()
```

# Set Ridge regression model and fitting

Set `mixture` is equal to zero refering the Ridge regression in `glmnet` since the 
위에서 구한 값으로 train2를 학습시킨다. 

*에러*
```{r message=FALSE, warning=FALSE}
elastic_model <- 
    linear_reg(penalty = tune_best$penalty, # 0.095
               mixture = tune_best$mixture) %>%
    set_engine("glmnet")
# elastic_fit <- 
#   elastic_model %>% 
#   fit(sale_price ~ ., data = train2)
options(max.print = 10)
elastic_fit %>% 
    tidy() %>% 
    filter(estimate > 0.001)
```

# Prediction and submit

```{r warning=FALSE}
result <- predict(elastic_fit, test2)
result %>% head()
```

```{r}
submission <- read_csv(file.path(file_path, "sample_submission.csv"))
submission$SalePrice <- exp(result$.pred)
write.csv(submission, row.names = FALSE,
          "lecture5-1.csv")
```

